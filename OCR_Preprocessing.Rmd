---
title: "OCR_Pre Processing"
output: html_notebook
---

```{r setup}
library(tidyverse)
library(magick)
library(tesseract)
library(imagerExtra)
library(furrr)
```

```{r prepare_image}
# Thanks to https://www.r-bloggers.com/historical-newspaper-scraping-with-tesseract-and-r/ for providing a pre-processing scheme on picture

prepare_image <- function(image_path){
  image <- image_read(image_path)
  image <- image %>%
    image_modulate(brightness = 150) %>%
    image_convolve('DoG:0,0,2', scaling = '1000, 100%') %>%
    image_despeckle(times = 10)
  
  image
}

```

```{r OCR using prepare_image}
img <- prepare_image("img.jpg")
text <- tesseract::ocr(img)


```


```{r prepare_image2}
# Thanks to this post: https://cran.r-project.org/web/packages/imagerExtra/vignettes/OCR_with_imagerExtra.html
prepare_image2 <- function(image_path){
  image <- load.image(image_path)
  image <- image %>%
      DenoiseDCT(0.01) %>% 
      ThresholdAdaptive(., 0.1, range = c(0,1)) 
     
}
```


```{r Check apply UCR on one newspaper article, using prepare_image2 }
# In order to fix the contrast, use magick

img <- prepare_image2("img.jpg")
text <- OCR(img, engine = "eng")
```
Problems:
Break a word into two part when changing a new line
Contrast

However, the second image pre-processing algorithm works better after comparing with the first one. 
